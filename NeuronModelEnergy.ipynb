{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e832c9-97cf-4393-9f01-2fdf9433def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "     Month  Hour  DayOfWeek  Holiday  HVACUsage  LightingUsage  Temperature  \\\n",
      "0        7    15          3        0          0              0    31.133301   \n",
      "1        4     3          5        1          1              0    32.160465   \n",
      "2       11    10          5        0          1              1    34.952566   \n",
      "3        8    23          6        1          1              1    19.829930   \n",
      "4        5    22          7        1          1              0    15.807017   \n",
      "..     ...   ...        ...      ...        ...            ...          ...   \n",
      "995      6    23          2        1          0              1    17.465676   \n",
      "996      5     8          6        1          0              0    25.371234   \n",
      "997      6     2          4        1          1              0    19.916949   \n",
      "998      6     9          1        0          1              0    22.162794   \n",
      "999      7    18          6        0          1              0    34.790107   \n",
      "\n",
      "      Humidity  SquareFootage  Occupancy  RenewableEnergy  EnergyConsumption  \n",
      "0    64.215712    4530.000834  88.859928         0.216814          76.220572  \n",
      "1    77.449033    4849.799994  32.907378         0.669611          42.550693  \n",
      "2    37.127828    2495.475963  31.458763         0.970668          56.724133  \n",
      "3    49.106974    1944.486705  51.208858         0.175715          32.413459  \n",
      "4    57.736590    2867.423060  94.069019         0.597117          53.195298  \n",
      "..         ...            ...        ...              ...                ...  \n",
      "995  42.199765    3578.940838   6.560076         0.499036          61.457721  \n",
      "996  78.336711    4470.985361  69.061531         0.931535          61.521572  \n",
      "997  77.906906    1415.799987  57.240773         0.583333         103.676690  \n",
      "998  42.381582    4430.125030  40.451952         0.538384          94.031148  \n",
      "999  47.402598     768.930234  36.361145         0.454483          41.130018  \n",
      "\n",
      "[1000 rows x 12 columns]\n",
      "Removed 6 outliers.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexe\\AppData\\Local\\Temp\\ipykernel_13168\\1413219565.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_reduced = df.replace({'Monday': 1, 'Tuesday': 2, 'Wednesday': 3,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4179.3042 - mae: 58.3488 - val_loss: 428.4079 - val_mae: 16.8600\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 453.8019 - mae: 16.7123 - val_loss: 406.4958 - val_mae: 16.2028\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 460.7149 - mae: 16.8694 - val_loss: 401.1454 - val_mae: 16.4316\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 432.0661 - mae: 16.3836 - val_loss: 405.5896 - val_mae: 16.2442\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 435.6013 - mae: 16.2596 - val_loss: 401.5943 - val_mae: 16.3890\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 423.7983 - mae: 16.2629 - val_loss: 403.1009 - val_mae: 16.2082\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 401.5691 - mae: 15.8484 - val_loss: 398.2100 - val_mae: 16.1100\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 398.3167 - mae: 15.6422 - val_loss: 395.4842 - val_mae: 16.0178\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 382.1997 - mae: 15.4492 - val_loss: 399.7878 - val_mae: 15.9784\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 416.4095 - mae: 16.1622 - val_loss: 401.1951 - val_mae: 16.2809\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 414.4197 - mae: 15.9856 - val_loss: 390.6386 - val_mae: 15.9840\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 359.7830 - mae: 14.7087 - val_loss: 406.5653 - val_mae: 16.4316\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 407.1542 - mae: 16.3263 - val_loss: 414.7809 - val_mae: 16.6386\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 414.9608 - mae: 16.1111 - val_loss: 396.2126 - val_mae: 15.9706\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 394.9787 - mae: 15.9739 - val_loss: 402.0282 - val_mae: 15.8485\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 357.2835 - mae: 14.9293 - val_loss: 384.8416 - val_mae: 15.8374\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 415.8418 - mae: 16.1891 - val_loss: 390.1083 - val_mae: 15.8996\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 407.8669 - mae: 15.8867 - val_loss: 392.3813 - val_mae: 16.1088\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 381.3532 - mae: 15.6472 - val_loss: 414.3268 - val_mae: 16.2051\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 409.5444 - mae: 16.2958 - val_loss: 386.0077 - val_mae: 15.7619\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 392.0271 - mae: 15.4917 - val_loss: 380.2230 - val_mae: 15.7708\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 402.6369 - mae: 15.8456 - val_loss: 407.4262 - val_mae: 15.9846\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 403.4406 - mae: 15.9035 - val_loss: 388.4109 - val_mae: 15.7933\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 414.6666 - mae: 16.1846 - val_loss: 392.9693 - val_mae: 15.7027\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 392.0303 - mae: 15.8575 - val_loss: 386.5861 - val_mae: 15.9312\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 358.3795 - mae: 15.2200 - val_loss: 394.0340 - val_mae: 16.3141\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 347.5670 - mae: 14.9019 - val_loss: 380.7441 - val_mae: 15.8775\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 374.0609 - mae: 15.4240 - val_loss: 393.5277 - val_mae: 16.1948\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 362.2215 - mae: 15.0060 - val_loss: 459.2501 - val_mae: 17.6144\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 383.7362 - mae: 15.3716 - val_loss: 386.6109 - val_mae: 16.0592\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 347.2209 - mae: 14.7906 - val_loss: 390.1835 - val_mae: 15.7163\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 340.0633 - mae: 14.5486 - val_loss: 393.3948 - val_mae: 15.9092\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 374.4828 - mae: 15.3569 - val_loss: 383.3895 - val_mae: 16.0215\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 329.3181 - mae: 14.5048 - val_loss: 431.6482 - val_mae: 17.0386\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 354.9094 - mae: 15.2007 - val_loss: 395.0431 - val_mae: 16.0939\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 325.3557 - mae: 14.2549 - val_loss: 387.0938 - val_mae: 15.8459\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 381.9483 - mae: 15.7414 - val_loss: 390.0903 - val_mae: 15.9006\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 360.4630 - mae: 15.1705 - val_loss: 410.5509 - val_mae: 16.1202\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 382.2397 - mae: 15.3613 - val_loss: 391.4187 - val_mae: 16.1798\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 322.4607 - mae: 14.4206 - val_loss: 417.7361 - val_mae: 16.6739\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 340.7521 - mae: 14.9043 - val_loss: 412.3775 - val_mae: 16.7143\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 354.4938 - mae: 14.7976 - val_loss: 385.2582 - val_mae: 15.7714\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 300.5202 - mae: 13.6671 - val_loss: 391.9645 - val_mae: 15.8996\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 313.9088 - mae: 14.0261 - val_loss: 401.5057 - val_mae: 15.8648\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 342.5556 - mae: 14.6657 - val_loss: 395.6268 - val_mae: 15.8909\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 331.4351 - mae: 14.5559 - val_loss: 395.2097 - val_mae: 15.9602\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 335.5437 - mae: 14.5092 - val_loss: 425.1423 - val_mae: 16.3659\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 321.7819 - mae: 14.2269 - val_loss: 401.9377 - val_mae: 15.8025\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 326.0525 - mae: 14.2309 - val_loss: 415.6894 - val_mae: 16.6363\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 315.9277 - mae: 14.0531 - val_loss: 400.1700 - val_mae: 16.1506\n",
      "Test Loss (MSE): 400.1699\n",
      "Test Mean Absolute Error (MAE): 16.1506\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Predictions for EnergyConsumption:\n",
      "[ 82.53636   77.91145   91.06383   79.47802   78.157555  78.65619\n",
      "  68.885574  83.21362   74.69496   77.10275   65.005066  68.24041\n",
      "  61.98791   90.245026  70.73279   81.11842   83.633545  66.24019\n",
      "  72.030304  75.23001   81.31914   72.77332   72.6201    70.0686\n",
      "  77.518234  74.49899  101.49388   70.57456   70.131516  68.21912\n",
      "  84.48282   67.56314   75.57633   72.53528   80.29523   66.7664\n",
      "  64.72226   73.832275  77.8629    79.57634   67.32079   76.112564\n",
      "  60.62864   65.86966   67.048904  79.56363   83.54007   87.65863\n",
      "  65.77782   69.28078 ]\n",
      "Manual MAE: 16.1506\n",
      "23.477381025084572 per cent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Energy_Consumption_Dataset_AI.csv\"  # Replace with your dataset file path\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "   # exit()\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "df_reduced = df.replace({'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, \n",
    "                         'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7, \n",
    "                         'Yes': 1, 'No': 0, 'On': 0, 'Off': 1}).infer_objects(copy=False)\n",
    "\n",
    "# Step 2: Verify Data and remove outliers\n",
    "print(df_reduced)\n",
    "\n",
    "# Use IQR to detect and remove outliers\n",
    "Q1 = df_reduced.quantile(0.25)\n",
    "Q3 = df_reduced.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter the dataset\n",
    "df_cleaned = df_reduced[~((df_reduced < (Q1 - 1.5 * IQR)) | (df_reduced > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(f\"Removed {len(df_reduced) - len(df_cleaned)} outliers.\")\n",
    "\n",
    "# Step 3: Model Processing\n",
    "\n",
    "df_reduced = df_cleaned\n",
    "\n",
    "# Define input features (X) and target variable (y)\n",
    "X = df_reduced.drop(columns=[\"EnergyConsumption\"])  # Features\n",
    "y = df_reduced[\"EnergyConsumption\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the numerical features for better performance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Build the TensorFlow Model\n",
    "model = Sequential([\n",
    "    Dense(400, input_dim=X_train.shape[1], activation=\"relu\"),  # Input layer with 4 neurons\n",
    "    Dense(1280, activation=\"relu\"),                             # Hidden layer with 128 neurons\n",
    "    Dense(1, activation=\"linear\")                              # Output layer (1 neuron for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])  # Loss: Mean Squared Error, Metric: Mean Absolute Error\n",
    "\n",
    "# Step 3: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Loss (MSE): {loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Flatten the predictions to make them 1D\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "# Print first 50 predictions\n",
    "print(\"Predictions for EnergyConsumption:\")\n",
    "print(predictions[:50])\n",
    "\n",
    "# Calculate Mean Absolute Error manually (for comparison)\n",
    "mae_manual = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Manual MAE: {mae_manual:.4f}\")\n",
    "\n",
    "mre = np.mean(np.abs((y_test - predictions) / y_test))\n",
    "print(mre*100.0, 'per cent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f80c3-6680-4bc7-961f-757bda87dd71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
